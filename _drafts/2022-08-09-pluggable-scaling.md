---
title: <span style='font-family:Menlo, Courier, monospace'>=nil;</span>'s Pluggable Scaling.
layout: post
date: 2022-08-09
excerpt: What is Pluggable scaling?
author: Aleksey S, Mikhail K, Haresh G.
tags: dbms io
comments: false
---
# Introduction
Monolithic blockchains have suffered throughput bottleneck in terms of transactions/sec during peak utilization.
We saw gas prices on ethereum spike to 400+ gwei during a BAYC land sale event 
pushing [nft transactions](https://web3isgoinggreat.com/?id=popular-nft-mint-spikes-ethereum-gas-prices-opensea-transaction-fees-exceed-3500) 
as high as 3,500$. This inability to meet demand results in higher transaction costs and wait times for users. 
For technology to embrace mass adoption, it is inherent stability/bounds be provided even in 
high demand scenarios. Solution to address this have resulted in newer chains adopting different 
architectures such as subnets (Avalanche) , supernets (Polygon) or hub-spoke architectures such 
as Cosmos IBC & Polkadot. 

Another branch of these solutions have taken form of Optimistic/zk-rollups which inherit security 
from the base layer they are built on.The rollup centric solution is part of the ETH2 upgrade, 
which eventually plans to move to sharding to provide data availability to the rollups, with
the possibility of having data shards execute smart contracts in the future. Application specific 
chains are proposed to be built on top of rollups moving another degree away from the base layer.

Both approaches above silo the application on to a single network.

In this post we propose an alternative scaling mechanism comprising =nil;Foundation DBMS nodes 
which help scale a base layer using validity proofs for state and query by running a number of clusters 
in parallel to load balance the transaction load.


# Concepts

Following concepts will aid us in understanding the proposed solution.

**State/Query proofs** : These are validity proofs generated by =nil;DBMS nodes which prove the state
and a response to the query. Some networks inherently generate these (MINA/CELO) ; whilst those which do not
(ETH/SOLANA) these are implemented on a network basis by writing protocol and I/O adapters. Generation of the proof
has a cost associated with it (hardware/electricity) whilst for most use cases, verification costs
are to be expressed as transaction costs as the verifiers are deployed in smart contracts.

**Placeholder proof system** :
Placeholder is =nil's in-house proof system for which validity proofs are generated. Once a
proof system is implemented for a network, this allows a network to perform its local
consistency checks before committing/implementing associated logic.

**Clustering**:
When users notice a slowdown in response times (or higher costs) in DBMS , it is first identified 
what subset of the data is causing the spike and based on severity, it can be moved to its own partition or
database. Similarly, when we see spikes in usage of a subset of data in blockchain networks, 
the proposed approach is to move this to a different partition/db (network). 

This implies, your application data can reside in more than one db or can be wholly moved to a
different db cluster to ease the network.

# Model 

We define and compare two models and the parameters which govern them. Ethereum main-net is taken as a base for calculations,
this can with a change of parameters can be extrapolated to any other network.
- Single Cluster:  This behaves as the current ethereum main-net.
- Multiple Clusters: We take multiple ethereum alike clusters which run alongside a main ethereum cluster.They are their
  own networks, these could be app chains.

The model simulates transaction flows using a poisson distribution to map how many transactions enter 
the network (flow). Adjustments include a flow rate & elasticity constant, implying if the rate is high , 
the number of new transactions added to the network will reduce. Transaction fee & gas consumed are modelled 
using an exponential and log-normal distribution respectively. Further details can be found in the repo here. (TODO)
  
We observe outputs of transaction time,cost and price for current ethereum network.

## Single cluster



## Multi cluster

We modify the above parameters to simulate the same metrics of but instead of one , we have multiple  
ETH sub-cluster's running.


//TODO  : Verify these formulas
 Transaction Price = price adjustments to take into account transaction price. This now has a proof generation 
   & verification cost associated with it , computer per block. (TODO VERIFY)



## Assumptions
The following is a subset of variables/boundaries are assumed for the simulation. For the full list please see the code
```
Base hourly flowRate l0 :=  Daily Transactions/24 = ~55,000
Number of sub clusters := 10 (excluding 1 main cluster)
Main cluster load := 0.5 (50% , rest of the transactions are simulated on subclusters)
Gas consumed in average tx  := 80000
CPU hours to generate proof  := 8.4
Placehodler verifier gas consumption := 2,000,000
```

# Findings

## Gas Price

Gas price in single cluster configuration is higher and more volatile as the transaction flow registers more load.
In multi cluster setup, we observe gas price is stable and low as expected as the load is shared amongst 11 clusters.

## Average transaction Fees
Average price in single cluster setup is volatile with the gas price & load. In multi cluster configuration , 
we notice more stable transaction costs. A fair observation is also the cost of transaction is higher when 
low number of transactions are on the network as this cost is associated to proof generation/verification.
On average, the cost is much lower in multi cluster setup.

## Average wait time 

Average waiting time for a transaction to be cleared from mempool has more spikes under loads where 
transactions can be waiting to be confirmed from few seconds (high gas price) to 20 minutes. Multi cluster
configuration clears the mem-pools much quicker and there is no wait lag experienced by the user.

## Transactions stuck in mempool 

Any transaction which is in the mempool for over 1 hour is considered stuck for this conclusion. High variance
is observed in a single cluster configuration, while multi cluster configuration show no signs of backlog. 

# Conclusion

We conclude from the above findings that re-envisioning networks as clusters provides scalability benefits
without having to adopt or maintain complex architectures. The security provided is on par with existing
L2 solutions, with the ability to further fragment the application if the need be. 